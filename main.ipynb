{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add\n",
    "- Auto date for SPP file\n",
    "- Requirements.txt\n",
    "- What the df mean\n",
    "- Logic for group 3 as we are using merge on BP now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "start_window = pd.to_datetime('2024-08-19')\n",
    "end_window = pd.to_datetime('2024-09-29')\n",
    "\n",
    "input_file = \"SPP Pilot - Enrollment Data for AHT.xlsx\"\n",
    "sheet_name = \"Master List\"\n",
    "output_file = \"SPP_CA.csv\"\n",
    "column_name = \"Contract Account\"\n",
    "BMD = '//Nas1/CS Analytics/C2A_Prod/BMD.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using this cell in the main input cell\n",
    "def business_partner_join(BMD, input_file, output_file, sheet_name):\n",
    "    df = (pd.read_excel(input_file, sheet_name=sheet_name, engine=\"openpyxl\", dtype={'Contract Account': 'string'})).rename(columns={'Contract Account': 'contract_account'}).merge(\n",
    "        (pd.read_parquet(BMD, columns=['business_partner', 'contract_account'])).astype(str),\n",
    "    on = 'contract_account',\n",
    "    how = 'left')\n",
    "    \n",
    "    df.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_partner_join(BMD, input_file, output_file, sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_volume = (\n",
    "    pd.read_parquet('//Nas1/CS Analytics/C2A_Prod/FULL_CALL_VOLUME_DASHBOARD.parquet', columns=['segment_start', 'business_partner_id', 'segment_stop', 'vendor', 'username', 'call_id', 'ucid', 'media_id', 'handled_time', 'speech_l1_updated', 'node_l2', 'contract_account', 'prorated_call_new', 'node_l3'])\n",
    "    .assign(segment_start = lambda df: pd.to_datetime(df['segment_start']),\n",
    "            segment_stop = lambda df: pd.to_datetime(df['segment_stop']))\n",
    "    .rename(columns={'call_id': 'CALL_ID', 'media_id': 'MEDIA_ID', 'business_partner_id': 'business_partner'})\n",
    "    .query(\"segment_start >= '2024-08-19' and segment_stop < '2024-09-29'\") #change this to the variables\n",
    "    .query(\"speech_l1_updated == 'COLLECTIONS' & node_l2 == 'SPP'\")\n",
    "    .dropna(subset=['contract_account'])\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "call_volume['business_partner'] = call_volume['business_partner'].astype(str)\n",
    "call_volume['contract_account'] = call_volume['contract_account'].astype(str)\n",
    "\n",
    "spp_pilot_contract_accounts = (\n",
    "    pd.read_csv(output_file, dtype={'business_partner': 'string', 'contract_account': 'string'}).rename(columns={'business_partner': 'pilot_business_partner', 'contract_account': 'pilot_contract_account'})[['pilot_business_partner', 'pilot_contract_account']]\n",
    ")\n",
    "\n",
    "spp_pilot = (\n",
    "    pd.read_csv(output_file, dtype={'business_partner': 'string', 'contract_account': 'string'}).rename(columns={'Opt-In Date': 'pilot_start_date'})[['business_partner', 'pilot_start_date', 'contract_account', 'Plan Created by']]\n",
    "    .assign(\n",
    "        pilot_start_date=lambda x: pd.to_datetime(x['pilot_start_date']),\n",
    "    )\n",
    "    .assign(\n",
    "        pilot_start_date_only=lambda x: x['pilot_start_date'].dt.date\n",
    "    )\n",
    ")\n",
    "\n",
    "spp_enrolled = (\n",
    "    pd.read_parquet('//Nas1/CS Analytics/C2A_Prod/PAYMENT_PLANS.parquet', columns=['contract_account', 'payment_plan_type', 'business_partner'])\n",
    "    .query(\"payment_plan_type == 'SPP'\")\n",
    "    .merge(\n",
    "        pd.read_parquet('//Nas1/CS Analytics/C2A_Prod/INSTALLMENT_PLANS.parquet', columns=['deactivation_date', 'plan_start_date', 'plan_end_date', 'contract_account']), on = 'contract_account', how = 'inner'\n",
    "    )\n",
    "    .drop_duplicates()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plan start date is betwn 8/19 and 9/29, also before 8/19. ! All of the people active in the window\n",
    "# All of the people who poted in for the pilot program\n",
    "# Join with call volume, after the call they enrolled in SPP, and opted out of pilot program ~pilot CA\n",
    "\n",
    "# Number of SPP enrollments, at any time is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1211897, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spp_enrolled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212, 18)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group 1\n",
    "spp_pitch_calls_pilot_accepted = spp_pilot.merge(\n",
    "    call_volume,\n",
    "    on = 'business_partner',\n",
    "    how = 'inner'\n",
    ")\n",
    "\n",
    "spp_pitch_calls_pilot_accepted = spp_pitch_calls_pilot_accepted.loc[\n",
    "    spp_pitch_calls_pilot_accepted['pilot_start_date'] >= spp_pitch_calls_pilot_accepted['segment_start']\n",
    "].drop_duplicates()\n",
    "\n",
    "spp_pitch_calls_pilot_accepted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is simply exporting the SPP pilot accepted but there were no calls\n",
    "spp_pitch_no_calls_pilot_accepted = spp_pilot.merge(\n",
    "    call_volume,\n",
    "    on = 'business_partner',\n",
    "    how = 'outer',\n",
    "    indicator = True\n",
    ").query(\"_merge == 'left_only'\")\n",
    "\n",
    "spp_pitch_no_calls_pilot_accepted = spp_pitch_no_calls_pilot_accepted.drop_duplicates(subset={'contract_account_x'})\n",
    "spp_pitch_no_calls_pilot_accepted.to_excel('No_calls_pilot_accepted.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2384, 16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group 2\n",
    "spp_enrolled_not_pilot = spp_enrolled.assign(\n",
    "    effective_end_date = spp_enrolled['deactivation_date'].fillna(spp_enrolled['plan_end_date'])\n",
    ").query(\n",
    "    \"(plan_start_date <= @end_window) & (effective_end_date >= @start_window)\"\n",
    ").loc[\n",
    "    ~spp_enrolled['contract_account'].isin(spp_pilot_contract_accounts['pilot_contract_account'])\n",
    "].drop(\n",
    "    columns = ['deactivation_date', 'plan_end_date', 'effective_end_date', 'payment_plan_type']\n",
    ")\n",
    "\n",
    "spp_pitch_calls = spp_enrolled_not_pilot.merge(\n",
    "    call_volume,\n",
    "    on = 'business_partner',\n",
    "    how = 'inner'\n",
    ")\n",
    "\n",
    "spp_pitch_calls = spp_pitch_calls.loc[\n",
    "    spp_pitch_calls['plan_start_date'] >= spp_pitch_calls['segment_start']\n",
    "].drop_duplicates()\n",
    "\n",
    "spp_pitch_calls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contract accounts present in call volume but not in SPP Pilot or SPP Enrolled stored\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4343, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group 3\n",
    "spp_combined_accounts = pd.concat([\n",
    "    spp_pilot['contract_account'], \n",
    "    spp_enrolled_not_pilot['contract_account']\n",
    "]).drop_duplicates()\n",
    "\n",
    "accounts_not_in_spp = call_volume[\n",
    "    ~call_volume['contract_account'].isin(spp_combined_accounts)\n",
    "]\n",
    "accounts_not_in_spp = accounts_not_in_spp.drop_duplicates()\n",
    "print(\"Contract accounts present in call volume but not in SPP Pilot or SPP Enrolled stored\")\n",
    "accounts_not_in_spp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_filter_by_closest_date(df, business_partner_column, date_column, segment_start_column, node_column):\n",
    "    if df[business_partner_column].nunique() == df.shape[0]:\n",
    "        print(\"Good to go: All values in the specified column are unique.\")\n",
    "    else:\n",
    "        print(\"Warning: Some values are duplicated in the specified column.\")\n",
    "    df['date_diff'] = (df[date_column] - df[segment_start_column])\n",
    "    \n",
    "    def get_closest_row(group):\n",
    "        if len(group) == 1:\n",
    "            return group.iloc[0]\n",
    "        \n",
    "        spp_enroll_rows = group[group[node_column] == 'SPP ENROLL']\n",
    "        \n",
    "        if len(spp_enroll_rows) == len(group):\n",
    "            return spp_enroll_rows.loc[spp_enroll_rows['date_diff'].idxmin()]\n",
    "        \n",
    "        if not spp_enroll_rows.empty:\n",
    "            return spp_enroll_rows.loc[spp_enroll_rows['date_diff'].idxmin()]\n",
    "        \n",
    "        return group.loc[group['date_diff'].idxmin()]\n",
    "    \n",
    "    closest_df = df.groupby(business_partner_column).apply(get_closest_row).reset_index(drop=True)\n",
    "    closest_df = closest_df.drop(columns=['date_diff'])\n",
    "    closest_df = closest_df.drop_duplicates()\n",
    "    \n",
    "    return closest_df\n",
    "\n",
    "def calculate_average_handle_time(df, handle_time_column):\n",
    "    total_handle_time = df[handle_time_column].sum()\n",
    "    total_prorated = df['prorated_call_new'].sum()\n",
    "    average_handle_time = total_handle_time / total_prorated \n",
    "    return total_handle_time, average_handle_time\n",
    "\n",
    "# df_filtered = check_and_filter_by_closest_date(call_volume, 'contract_account', 'plan_start_date', 'segment_start')\n",
    "# avg_handle_time = calculate_average_handle_time(call_volume, 'handle_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some values are duplicated in the specified column.\n",
      "Total handle time: 147225 and Total number of calls: 182 and Avg Handle Time: 806.6339797893351\n"
     ]
    }
   ],
   "source": [
    "# Group 1 value calculation\n",
    "group1_filtered = check_and_filter_by_closest_date(spp_pitch_calls_pilot_accepted, 'business_partner', 'pilot_start_date', 'segment_start', 'node_l3')\n",
    "group1_handle_time, group1_avg_handle_time = calculate_average_handle_time(group1_filtered, 'handled_time')\n",
    "print(f\"Total handle time: {group1_handle_time} and Total number of calls: {group1_filtered.shape[0]} and Avg Handle Time: {group1_avg_handle_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some values are duplicated in the specified column.\n",
      "Total handle time: 1349830 and Total number of calls: 1774 and Avg Handle Time: 749.2455554156063\n"
     ]
    }
   ],
   "source": [
    "# Group 2 value calculation\n",
    "group2_filtered = check_and_filter_by_closest_date(spp_pitch_calls, 'business_partner', 'plan_start_date', 'segment_start', 'node_l3')\n",
    "group2_handle_time, group2_avg_handle_time = calculate_average_handle_time(group2_filtered, 'handled_time')\n",
    "print(f\"Total handle time: {group2_handle_time} and Total number of calls: {group2_filtered.shape[0]} and Avg Handle Time: {group2_avg_handle_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total handle time: 3470717 and Total number of calls: 4343 and Avg Handle Time: 788.4077985002515\n"
     ]
    }
   ],
   "source": [
    "# Group 3 value calculation\n",
    "group3_handle_time, group3_avg_handle_time = calculate_average_handle_time(accounts_not_in_spp, 'handled_time')\n",
    "print(f\"Total handle time: {group3_handle_time} and Total number of calls: {accounts_not_in_spp.shape[0]} and Avg Handle Time: {group3_avg_handle_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spp_pitch_calls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Can we have multiple CA's attached to the same BP who are in SPP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adhoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
